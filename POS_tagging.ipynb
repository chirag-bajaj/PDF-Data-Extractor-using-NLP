{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_tagging.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WShuGiRAL-6W",
        "colab_type": "code",
        "outputId": "171e8ac0-5f88-4eac-aae1-d7640e566b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.core import Activation, Dense, Dropout, RepeatVector, SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import nltk\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XZf6IaeNLoA4",
        "colab_type": "code",
        "outputId": "f60eed37-36c7-4602-c05d-d1b5681efebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "model1 = load_model('model1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "415XzAVPMR6-",
        "colab_type": "code",
        "outputId": "620bd580-6e1c-4c8d-9f05-d073585a31b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download('treebank')\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        " \n",
        "#print(tagged_sentences[0])\n",
        "#print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "#print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
        " \n",
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(np.array(sentence))\n",
        "    sentence_tags.append(np.array(tags))\n",
        "    \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        " \n",
        "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)\n",
        "\n",
        "def logits_to_tokens(sequences, index):\n",
        "  token_sequences = []\n",
        "  for categorical_sequence in sequences:\n",
        "    token_sequence = []\n",
        "    for categorical in categorical_sequence:\n",
        "      token_sequence.append(index[np.argmax(categorical)])\n",
        "    token_sequences.append(token_sequence)\n",
        "  return token_sequence\n",
        "\n",
        "test_samples = [\n",
        "    \"my name is John Patel, Kandarp Kakkad, Chirag Bajaj .\".split(),\n",
        "]\n",
        "\n",
        "words, tags = set([]), set([])\n",
        "\n",
        "for s in test_samples:\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        "        \n",
        "        \n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0\n",
        "\n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        "\n",
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=100, padding='post')\n",
        "print(test_samples)\n",
        "predictions = model1.predict(test_samples_X)\n",
        "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[['my', 'name', 'is', 'John', 'Patel,', 'Kandarp', 'Kakkad,', 'Chirag', 'Bajaj', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b87c618b2aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag2index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-b87c618b2aaa>\u001b[0m in \u001b[0;36mlogits_to_tokens\u001b[0;34m(sequences, index)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtoken_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_sequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mtoken_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtoken_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 67"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2LW12ytNO-d0",
        "colab_type": "code",
        "outputId": "75a052c0-6161-4de4-bf4f-fdedc3155272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "test_samples = [\n",
        "    \"and but is John Patel, Kandarp Kakkad, Chirag Bajaj .\".split(),\n",
        "]\n",
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        " \n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=100, padding='post')\n",
        "print(test_samples)\n",
        "predictions = model1.predict(test_samples_X)\n",
        "print(predictions)\n",
        "print(predictions.argmax)\n",
        "#print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['and', 'but', 'is', 'John', 'Patel,', 'Kandarp', 'Kakkad,', 'Chirag', 'Bajaj', '.']]\n",
            "[[[3.0971918e-02 1.5803077e-04 1.7182190e-05 ... 2.3657225e-04\n",
            "   1.3137695e-04 1.4381931e-04]\n",
            "  [4.7612561e-05 1.1261850e-06 4.0319219e-07 ... 8.1519482e-07\n",
            "   6.6128212e-07 6.3453359e-07]\n",
            "  [7.5643446e-05 2.7651879e-05 3.0789677e-05 ... 2.1018252e-05\n",
            "   1.6598637e-05 1.6886481e-05]\n",
            "  ...\n",
            "  [9.9999988e-01 1.4703766e-12 2.8214809e-15 ... 3.2447669e-12\n",
            "   6.1056623e-13 1.3287751e-12]\n",
            "  [9.9999940e-01 9.1841994e-12 4.1560312e-14 ... 2.1294603e-11\n",
            "   4.4837883e-12 9.0597998e-12]\n",
            "  [9.9998307e-01 3.7671102e-10 7.2925312e-12 ... 9.1399860e-10\n",
            "   2.3326321e-10 4.0904938e-10]]]\n",
            "<built-in method argmax of numpy.ndarray object at 0x7fd8214634e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TWKDmObWb7OQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}